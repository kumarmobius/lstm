name: Partial Fit VAE Model
description: Loads an instantiated VAE and a .pth checkpoint, applies weights, partial-fits (fine-tunes) on incoming train data, and saves the model & epoch loss in the same style as Train VAE Model.
inputs:
  - {name: model, type: Model}
  - {name: pth_file, type: Model, description: "Checkpoint (.pth/.pt) containing state_dict or wrapper"}
  - {name: train_loader, type: Dataset}
  - {name: config, type: String}
outputs:
  - {name: trained_model, type: Model}
  - {name: epoch_loss, type: String}
implementation:
  container:
    image: nikhilv215/nesy-factory:v22
    command:
      - python3
      - -u
      - -c
      - |
        import argparse
        import json
        import os
        import pickle
        import sys
        import numpy as np
        import torch
        import torch.nn as nn
        import torch.optim as optim
        import traceback

        parser = argparse.ArgumentParser()
        parser.add_argument('--model', type=str, required=True)
        parser.add_argument('--pth_file', type=str, required=True)
        parser.add_argument('--train_loader', type=str, required=True)
        parser.add_argument('--config', type=str, required=True)
        parser.add_argument('--trained_model', type=str, required=True)
        parser.add_argument('--epoch_loss', type=str, required=True)
        args = parser.parse_args()

        # --- helpers to handle Kubeflow/Argo mounted dirs ---
        def find_actual_file(path, prefer_exts=(".pth", ".pt")):
            # direct file
            if os.path.isfile(path):
                return path
            # sometimes mounted as path/data
            data_path = os.path.join(path, "data")
            if os.path.isfile(data_path):
                return data_path
            # if directory, search for preferred extensions first
            if os.path.isdir(path):
                candidates = []
                for root, dirs, files in os.walk(path):
                    for f in files:
                        if f.startswith('.'):
                            continue
                        candidates.append(os.path.join(root, f))
                if not candidates:
                    raise FileNotFoundError(f"No files found inside directory: {path}")
                for ext in prefer_exts:
                    for c in candidates:
                        if c.lower().endswith(ext):
                            return c
                candidates = sorted(candidates)
                return candidates[0]
            return path

        def load_torch_obj(path):
            p = find_actual_file(path)
            print(f"[DEBUG] load_torch_obj -> resolved path: {p}")
            if not os.path.exists(p):
                raise FileNotFoundError(p)
            if os.path.isdir(p):
                raise IsADirectoryError(p)
            # try torch.load then pickle fallback
            try:
                return torch.load(p, map_location='cpu')
            except Exception as e:
                print(f"[DEBUG] torch.load failed: {e}; trying pickle...")
                try:
                    with open(p, 'rb') as f:
                        return pickle.load(f)
                except Exception as e2:
                    print(f"[DEBUG] pickle load failed: {e2}")
                    raise RuntimeError(f"Failed to load object from {p}") from e2

        def extract_state_dict(ckpt):
            if isinstance(ckpt, dict):
                if 'model_state' in ckpt:
                    return ckpt['model_state']
                if 'state_dict' in ckpt:
                    return ckpt['state_dict']
                # heuristic: if keys look like tensors (contain '.'), treat as state_dict
                if any(isinstance(k, str) and '.' in k for k in ckpt.keys()):
                    return ckpt
            return None

        def strip_module_prefix(state_dict):
            new = {}
            for k, v in state_dict.items():
                if k.startswith('module.'):
                    new[k.replace('module.', '', 1)] = v
                else:
                    new[k] = v
            return new

        # --- load config ---
        config = {}
        if args.config and args.config.strip():
            try:
                config = json.loads(args.config)
            except Exception as e:
                print("[partial_fit_vae] Warning: failed to parse config JSON, using defaults:", e)

        finetune_epochs = int(config.get('finetune_epochs', 3))
        finetune_lr = float(config.get('finetune_lr', 1e-4))
        beta = float(config.get('beta', 1.0))
        batch_size = int(config.get('batch_size', 32))
        use_all_train = bool(config.get('use_all_train_data', False))

        print(f"[partial_fit_vae] finetune_epochs={finetune_epochs}, finetune_lr={finetune_lr}, beta={beta}, batch_size={batch_size}")

        # --- load instantiated model object (pickle) ---
        try:
            print("[partial_fit_vae] Loading model (instantiated) from:", args.model)
            with open(args.model, 'rb') as f:
                model_obj = pickle.load(f)
        except Exception as e:
            print("[partial_fit_vae] ERROR loading model object:", e)
            traceback.print_exc()
            sys.exit(1)

        # ensure model is on cpu first
        try:
            model_obj = model_obj.to('cpu')
        except Exception:
            pass

        # verify model is nn.Module-like
        if not hasattr(model_obj, 'train') or not hasattr(model_obj, 'eval'):
            print("[partial_fit_vae] ERROR: provided model does not look like a torch model instance.")
            sys.exit(1)

        # --- load checkpoint and apply weights ---
        try:
            print("[partial_fit_vae] Loading checkpoint from:", args.pth_file)
            ckpt_raw = load_torch_obj(args.pth_file)
            state = extract_state_dict(ckpt_raw)
            if state is None:
                # maybe full model instance
                if hasattr(ckpt_raw, 'state_dict'):
                    try:
                        model_obj.load_state_dict(ckpt_raw.state_dict(), strict=False)
                        print("[partial_fit_vae] Loaded weights from full model instance in checkpoint.")
                    except Exception as e:
                        print("[partial_fit_vae] Failed to load state from full model instance:", e)
                        traceback.print_exc()
                        sys.exit(1)
                else:
                    try:
                        model_obj.load_state_dict(ckpt_raw, strict=False)
                        print("[partial_fit_vae] Loaded checkpoint as direct state_dict.")
                    except Exception as e:
                        print("[partial_fit_vae] Direct load failed:", e)
                        traceback.print_exc()
                        sys.exit(1)
            else:
                state = strip_module_prefix(state)
                model_obj.load_state_dict(state, strict=False)
                print("[partial_fit_vae] Applied extracted state_dict to model (strict=False).")
        except Exception as e:
            print("[partial_fit_vae] ERROR applying checkpoint:", e)
            traceback.print_exc()
            sys.exit(1)

        # move model to device
        device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
        print("[partial_fit_vae] Using device:", device)
        model_obj = model_obj.to(device)

        # --- load train data (pickle loader or dict-loader) ---
        try:
            print("[partial_fit_vae] Loading train loader from:", args.train_loader)
            with open(args.train_loader, 'rb') as f:
                train_data = pickle.load(f)
            if isinstance(train_data, dict) and 'loader' in train_data:
                train_loader_obj = train_data['loader']
            else:
                train_loader_obj = train_data
        except Exception as e:
            print("[partial_fit_vae] ERROR loading train_loader:", e)
            traceback.print_exc()
            sys.exit(1)

        # ensure iterable
        if not hasattr(train_loader_obj, '__iter__'):
            print("[partial_fit_vae] ERROR: train_loader is not iterable")
            sys.exit(1)

        # --- prepare for partial-fit: seed a small replay buffer or use last batch ---
        # For simplicity, use last batch as new incoming data or all data if requested
        all_batches = []
        try:
            for b in train_loader_obj:
                # allow generator-type loaders; collect only a limited number to avoid OOM
                all_batches.append(b)
            print(f"[partial_fit_vae] Collected {len(all_batches)} batches from train_loader")
        except Exception as e:
            print("[partial_fit_vae] Warning collecting batches:", e)
            all_batches = []

        if use_all_train and len(all_batches) > 0:
            # combine all batches
            X_list = []
            for batch in all_batches:
                data = batch[0] if (isinstance(batch, (list, tuple)) and len(batch) >= 1) else batch
                if isinstance(data, torch.Tensor):
                    X_list.append(data.detach().cpu())
                else:
                    X_list.append(torch.tensor(data, dtype=torch.float32))
            X_new = torch.cat(X_list, dim=0).to(device)
            train_iter = [(X_new, )]  # one big batch
            print("[partial_fit_vae] Using all train data for finetune")
        else:
            # use last batch (streaming style)
            if len(all_batches) > 0:
                last = all_batches[-1]
                X_new = last[0] if (isinstance(last, (list, tuple)) and len(last) >= 1) else last
                if not isinstance(X_new, torch.Tensor):
                    X_new = torch.tensor(X_new, dtype=torch.float32)
                train_iter = [(X_new.to(device), )]
                print("[partial_fit_vae] Using last batch for finetune")
            else:
                # fallback: try iter(train_loader_obj) once
                try:
                    it = iter(train_loader_obj)
                    sample = next(it)
                    X_new = sample[0] if (isinstance(sample, (list, tuple)) and len(sample) >= 1) else sample
                    if not isinstance(X_new, torch.Tensor):
                        X_new = torch.tensor(X_new, dtype=torch.float32)
                    train_iter = [(X_new.to(device), )]
                    print("[partial_fit_vae] Using sampled batch from train_loader for finetune")
                except Exception as e:
                    print("[partial_fit_vae] ERROR: could not obtain any batch for finetune:", e)
                    traceback.print_exc()
                    sys.exit(1)

        # --- build optimizer and loss (simple finetune) ---
        optimizer = optim.Adam(model_obj.parameters(), lr=finetune_lr)
        epoch_loss_data = []

        print("[partial_fit_vae] Starting finetune loop...")
        model_obj.train()
        for epoch in range(finetune_epochs):
            total_loss = 0.0
            total_recon = 0.0
            total_kl = 0.0
            nb = 0

            for entry in train_iter:
                data = entry[0]
                # If data has batch dimension 1+, split into mini-batches
                if data.size(0) > batch_size:
                    # create simple DataLoader-like splitting
                    for i in range(0, data.size(0), batch_size):
                        xb = data[i:i+batch_size].to(device)
                        optimizer.zero_grad()
                        out = model_obj(xb)
                        # parse VAE outputs like in training code
                        if isinstance(out, dict):
                            possible_recon = ['reconstruction','recon','x_recon','decoded','output']
                            recon = None
                            for k in possible_recon:
                                if k in out:
                                    recon = out[k]; break
                            mu = out.get('mu', out.get('mean', None))
                            logvar = out.get('logvar', out.get('log_var', None))
                            if recon is None:
                                recon = list(out.values())[0]
                            if mu is None:
                                mu = torch.zeros(xb.size(0), getattr(model_obj, 'latent_dim', 16)).to(device)
                            if logvar is None:
                                logvar = torch.zeros(xb.size(0), getattr(model_obj, 'latent_dim', 16)).to(device)
                        elif isinstance(out, tuple):
                            if len(out) >= 3:
                                recon, mu, logvar = out[0], out[1], out[2]
                            elif len(out) == 2:
                                recon = out[0]
                                lat = out[1]
                                if isinstance(lat, tuple) and len(lat) >= 2:
                                    mu, logvar = lat[0], lat[1]
                                else:
                                    mu = torch.zeros(xb.size(0), getattr(model_obj, 'latent_dim', 16)).to(device)
                                    logvar = torch.zeros(xb.size(0), getattr(model_obj, 'latent_dim', 16)).to(device)
                            else:
                                recon = out[0]
                                mu = torch.zeros(xb.size(0), getattr(model_obj, 'latent_dim', 16)).to(device)
                                logvar = torch.zeros(xb.size(0), getattr(model_obj, 'latent_dim', 16)).to(device)
                        else:
                            recon = out
                            mu = torch.zeros(xb.size(0), getattr(model_obj, 'latent_dim', 16)).to(device)
                            logvar = torch.zeros(xb.size(0), getattr(model_obj, 'latent_dim', 16)).to(device)

                        # compute losses
                        recon_loss = nn.MSELoss()(recon, xb)
                        kl = -0.5 * torch.sum(1 + logvar - mu.pow(2) - logvar.exp())
                        kl = kl / xb.size(0)
                        loss = recon_loss + beta * kl
                        loss.backward()
                        optimizer.step()

                        total_loss += loss.item()
                        total_recon += recon_loss.item()
                        total_kl += kl.item()
                        nb += 1
                else:
                    xb = data.to(device)
                    optimizer.zero_grad()
                    out = model_obj(xb)
                    # parse as above (reuse logic)
                    if isinstance(out, dict):
                        possible_recon = ['reconstruction','recon','x_recon','decoded','output']
                        recon = None
                        for k in possible_recon:
                            if k in out:
                                recon = out[k]; break
                        mu = out.get('mu', out.get('mean', None))
                        logvar = out.get('logvar', out.get('log_var', None))
                        if recon is None:
                            recon = list(out.values())[0]
                        if mu is None:
                            mu = torch.zeros(xb.size(0), getattr(model_obj, 'latent_dim', 16)).to(device)
                        if logvar is None:
                            logvar = torch.zeros(xb.size(0), getattr(model_obj, 'latent_dim', 16)).to(device)
                    elif isinstance(out, tuple):
                        if len(out) >= 3:
                            recon, mu, logvar = out[0], out[1], out[2]
                        elif len(out) == 2:
                            recon = out[0]
                            lat = out[1]
                            if isinstance(lat, tuple) and len(lat) >= 2:
                                mu, logvar = lat[0], lat[1]
                            else:
                                mu = torch.zeros(xb.size(0), getattr(model_obj, 'latent_dim', 16)).to(device)
                                logvar = torch.zeros(xb.size(0), getattr(model_obj, 'latent_dim', 16)).to(device)
                        else:
                            recon = out[0]
                            mu = torch.zeros(xb.size(0), getattr(model_obj, 'latent_dim', 16)).to(device)
                            logvar = torch.zeros(xb.size(0), getattr(model_obj, 'latent_dim', 16)).to(device)
                    else:
                        recon = out
                        mu = torch.zeros(xb.size(0), getattr(model_obj, 'latent_dim', 16)).to(device)
                        logvar = torch.zeros(xb.size(0), getattr(model_obj, 'latent_dim', 16)).to(device)

                    recon_loss = nn.MSELoss()(recon, xb)
                    kl = -0.5 * torch.sum(1 + logvar - mu.pow(2) - logvar.exp())
                    kl = kl / xb.size(0)
                    loss = recon_loss + beta * kl
                    loss.backward()
                    optimizer.step()

                    total_loss += loss.item()
                    total_recon += recon_loss.item()
                    total_kl += kl.item()
                    nb += 1

            # record epoch stats
            if nb > 0:
                avg_total = total_loss / nb
                avg_recon = total_recon / nb
                avg_kl = total_kl / nb
            else:
                avg_total = avg_recon = avg_kl = 0.0

            epoch_loss_data.append({
                'epoch': epoch + 1,
                'loss': avg_total,
                'custom_metrics': {
                    'recon_loss': avg_recon,
                    'kl_loss': avg_kl
                }
            })
            print(f"[partial_fit_vae] Epoch {epoch+1}/{finetune_epochs} -> loss={avg_total:.6f}, recon={avg_recon:.6f}, kl={avg_kl:.6f}")

        # --- save epoch loss (JSON) ---
        try:
            out_dir_epoch_loss = os.path.dirname(args.epoch_loss)
            if out_dir_epoch_loss and not os.path.exists(out_dir_epoch_loss):
                os.makedirs(out_dir_epoch_loss, exist_ok=True)
            with open(args.epoch_loss, 'w') as f:
                json.dump(epoch_loss_data, f, indent=2)
            print(f"[partial_fit_vae] Saved epoch loss to {args.epoch_loss}")
        except Exception as e:
            print("[partial_fit_vae] ERROR saving epoch loss:", e)
            traceback.print_exc()

        # --- save the fine-tuned model (same style as Train VAE Model) ---
        try:
            out_model_dir = os.path.dirname(args.trained_model)
            if out_model_dir and not os.path.exists(out_model_dir):
                os.makedirs(out_model_dir, exist_ok=True)
            # move to cpu before saving to be consistent with Train VAE Model
            try:
                model_to_save = model_obj.cpu()
            except Exception:
                model_to_save = model_obj
            with open(args.trained_model, 'wb') as f:
                pickle.dump(model_to_save, f)
            print(f"[partial_fit_vae] Saved fine-tuned VAE model to {args.trained_model}")
        except Exception as e:
            print("[partial_fit_vae] ERROR saving model:", e)
            traceback.print_exc()
            sys.exit(1)

        # final stats
        try:
            total_params = sum(p.numel() for p in model_obj.parameters())
            trainable_params = sum(p.numel() for p in model_obj.parameters() if p.requires_grad)
            print(f"[partial_fit_vae] Model parameters: total={total_params}, trainable={trainable_params}")
        except Exception:
            pass

        print("[partial_fit_vae] Partial-fit VAE completed.")
    args:
      - --model
      - {inputPath: model}
      - --pth_file
      - {inputPath: pth_file}
      - --train_loader
      - {inputPath: train_loader}
      - --config
      - {inputValue: config}
      - --trained_model
      - {outputPath: trained_model}
      - --epoch_loss
      - {outputPath: epoch_loss}
