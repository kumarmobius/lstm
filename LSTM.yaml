name: Partial Fit LSTM v6
inputs:
  - {name: model_object, type: Model, description: "Path to torch-saved model object (should contain an instantiated model or a saved instance)."}
  - {name: pth_file, type: Model, description: "Path to the .pth checkpoint file to load weights from (state_dict or wrapper)."}
  - {name: train_loader, type: Dataset, description: "Path to a torch-saved train dataset/iterable (DataLoader, TensorDataset, or list of (x,y) pairs)."}
  - {name: test_loader, type: Dataset, description: "Path to a torch-saved test dataset/iterable (for validation)."}
  - {name: input_dim, type: String, description: "Input dimension (string or int). Used only if model needs to be re-instantiated (not required if model instance provided)."}
  - {name: model_config, type: String, description: "Optional JSON string with model hyperparameters (learning_rate, finetune_epochs, etc.)."}

outputs:
  - {name: updated_pth_dir, type: Model, description: "Directory where updated_model.pth will be saved automatically after partial_fit."}

implementation:
  container:
    image: gurpreetgandhi/nesy-factory:v25
    command:
      - python3
      - -u
      - -c
      - |
        import argparse, os, sys, json, copy, random, traceback, pickle, glob
        import torch
        import torch.nn as nn
        import numpy as np
        from torch.utils.data import TensorDataset, DataLoader, ConcatDataset

        parser = argparse.ArgumentParser(description="Partial-fit LSTM using torch-saved inputs")
        parser.add_argument("--model_object", required=True, help="Path to saved model object (.pt/.pth) OR a file containing an instantiated model")
        parser.add_argument("--pth_file", required=True, help="Checkpoint .pth file (weights) to load")
        parser.add_argument("--train_loader", required=True, help="Path to torch-saved train dataset / iterable")
        parser.add_argument("--test_loader", required=True, help="Path to torch-saved test dataset / iterable")
        parser.add_argument("--input_dim", required=False, default="", help="Input dimension (int or string) - optional")
        parser.add_argument("--model_config", required=False, default="", help="JSON string with hyperparams (optional)")
        parser.add_argument("--updated_pth_dir", required=True, help="Output directory to save updated_model.pth (this is an outputPath)")
        args = parser.parse_args()

        # --- helpers ---
        def find_actual_file(path, prefer_exts=(".pth", ".pt")):
            # direct file
            if os.path.isfile(path):
                return path

            # sometimes tools mount the file as `<path>/data`
            data_path = os.path.join(path, "data")
            if os.path.isfile(data_path):
                return data_path

            # if it's a directory, walk and find preferred files first
            if os.path.isdir(path):
                candidates = []
                for root, dirs, files in os.walk(path):
                    for f in files:
                        if f.startswith('.'):
                            continue
                        candidates.append(os.path.join(root, f))

                if not candidates:
                    raise FileNotFoundError(f"No files found inside directory: {path}")

                # prefer extensions in prefer_exts (in order)
                for ext in prefer_exts:
                    for c in candidates:
                        if c.lower().endswith(ext):
                            return c

                # fallback: return first candidate (deterministic sorted order)
                candidates = sorted(candidates)
                return candidates[0]

            # if we reach here, return original path so caller can handle error
            return path

        def load_torch_obj(path):
            actual_path = find_actual_file(path)
            print(f"[DEBUG] Attempting to load from: {actual_path}")

            if not os.path.exists(actual_path):
                raise FileNotFoundError(f"File not found: {actual_path}")

            if os.path.isdir(actual_path):
                raise IsADirectoryError(f"Path is a directory, not a file: {actual_path}")

            # Try torch.load first (weights_only=False allows loading full object)
            try:
                return torch.load(actual_path, map_location='cpu', weights_only=False)
            except TypeError:
                # older torch may not have weights_only arg
                try:
                    return torch.load(actual_path, map_location='cpu')
                except Exception as e:
                    print(f"[partial_fit] torch.load failed (second attempt): {e}")
                    # fall through to pickle attempt
            except Exception as e:
                print(f"[partial_fit] torch.load failed: {e}")

            # Try pickle as fallback
            try:
                print("[partial_fit] Attempting to load with pickle fallback...")
                with open(actual_path, 'rb') as f:
                    obj = pickle.load(f)
                print("[partial_fit] Successfully loaded with pickle")
                return obj
            except Exception as e2:
                print(f"[partial_fit] Pickle load failed: {e2}")
                raise RuntimeError(f"Failed to load object from {actual_path}") from e2

        def extract_state_dict(ckpt):
            # return a state_dict if possible
            if isinstance(ckpt, dict) and ('model_state' in ckpt or 'state_dict' in ckpt):
                return ckpt.get('model_state', ckpt.get('state_dict'))
            if isinstance(ckpt, dict) and any(isinstance(k, str) and ('.' in k) for k in ckpt.keys()):
                return ckpt
            return None

        def strip_module_prefix(state_dict):
            new_state = {}
            for k, v in state_dict.items():
                if k.startswith('module.'):
                    new_state[k.replace('module.', '', 1)] = v
                else:
                    new_state[k] = v
            return new_state

        class ReplayBuffer:
            def __init__(self, capacity=2000):
                self.capacity = int(capacity)
                self.X = []
                self.y = []
                self.n_seen = 0
            
            def add_batch(self, X_batch, y_batch):
                if isinstance(X_batch, torch.Tensor):
                    X_batch = X_batch.detach().cpu().numpy()
                if isinstance(y_batch, torch.Tensor):
                    y_batch = y_batch.detach().cpu().numpy()
                
                for xb, yb in zip(X_batch, y_batch):
                    self.n_seen += 1
                    if len(self.X) < self.capacity:
                        self.X.append(np.copy(xb))
                        self.y.append(np.copy(yb))
                    else:
                        prob = self.capacity / float(self.n_seen)
                        if random.random() < prob:
                            idx = random.randrange(self.capacity)
                            self.X[idx] = np.copy(xb)
                            self.y[idx] = np.copy(yb)
            
            def sample(self, k):
                if len(self.X) == 0:
                    return None, None
                k = min(k, len(self.X))
                idx = random.sample(range(len(self.X)), k)
                Xs = np.stack([self.X[i] for i in idx])
                ys = np.stack([self.y[i] for i in idx])
                return Xs, ys
            
            def __len__(self):
                return len(self.X)

        def iterable_from(obj):
            # Accept DataLoader, Dataset, list/tuple, or generator
            if hasattr(obj, '__iter__') and not isinstance(obj, dict):
                return obj
            raise RuntimeError("train/test object is not iterable - expected DataLoader/list/TensorDataset saved via torch.save")

        # --- load model object ---
        try:
            print("[partial_fit] Loading model object from:", args.model_object)
            model_obj = load_torch_obj(args.model_object)
        except Exception as e:
            print("[partial_fit] ERROR loading model_object:", e)
            traceback.print_exc()
            sys.exit(1)

        # If loaded object is an instantiated model, use it
        if hasattr(model_obj, 'eval') and hasattr(model_obj, 'train'):
            model = model_obj
            print("[partial_fit] Loaded model instance from file.")
        else:
            print("[partial_fit] The provided model_object does not appear to be an instantiated model.")
            print("[partial_fit] Please save/provide a torch-saved model instance (torch.save(model, path)). Aborting.")
            sys.exit(1)

        # --- load checkpoint weights and apply ---
        try:
            print("[partial_fit] Loading checkpoint weights from:", args.pth_file)
            ckpt = load_torch_obj(args.pth_file)
            state = extract_state_dict(ckpt)
            
            if state is None:
                # maybe ckpt is a full model instance
                if hasattr(ckpt, 'state_dict'):
                    try:
                        model.load_state_dict(ckpt.state_dict(), strict=False)
                        print("[partial_fit] Loaded weights from a full model saved in checkpoint.")
                    except Exception as e:
                        print("[partial_fit] Failed to load state from saved full model:", e)
                        sys.exit(1)
                else:
                    # try direct load
                    try:
                        model.load_state_dict(ckpt, strict=False)
                        print("[partial_fit] Loaded checkpoint as state_dict (direct).")
                    except Exception as e:
                        print("[partial_fit] Direct load failed:", e)
                        sys.exit(1)
            else:
                state = strip_module_prefix(state)
                model.load_state_dict(state, strict=False)
                print("[partial_fit] State dict loaded into model (strict=False).")
        except Exception as e:
            print("[partial_fit] ERROR applying checkpoint:", e)
            traceback.print_exc()
            sys.exit(1)

        # --- load config (from JSON string) ---
        model_config = {}
        if args.model_config and args.model_config.strip():
            try:
                model_config = json.loads(args.model_config)
                print("[partial_fit] Loaded model_config keys:", list(model_config.keys()))
            except Exception as e:
                print("[partial_fit] Warning: failed to parse model_config JSON string:", e)
                print("[partial_fit] Continuing with defaults.")

        base_lr = float(model_config.get('learning_rate', 1e-3))
        finetune_lr_factor = float(model_config.get('finetune_lr_factor', 0.1))
        finetune_epochs = int(model_config.get('finetune_epochs', 3))
        replay_capacity = int(model_config.get('replay_capacity', 2000))
        replay_samples = int(model_config.get('replay_samples', 256))
        batch_size = int(model_config.get('batch_size', 32))
        loss_name = model_config.get('loss_function', 'BCEWithLogitsLoss')
        use_all_train = bool(model_config.get('use_all_train_data', False))

        finetune_lr = base_lr * finetune_lr_factor

        print(f"[partial_fit] Hyperparameters: lr={finetune_lr:.6g}, epochs={finetune_epochs}, replay_cap={replay_capacity}, replay_samples={replay_samples}")

        # --- load train/test data objects (torch-saved) ---
        try:
            print("[partial_fit] Loading train_loader from:", args.train_loader)
            train_obj = load_torch_obj(args.train_loader)
            print("[partial_fit] Loading test_loader from:", args.test_loader)
            test_obj = load_torch_obj(args.test_loader)
        except Exception as e:
            print("[partial_fit] ERROR loading train/test objects:", e)
            traceback.print_exc()
            sys.exit(1)

        try:
            train_iter = iterable_from(train_obj)
            test_iter = iterable_from(test_obj)
        except Exception as e:
            print("[partial_fit] ERROR: train/test object not iterable:", e)
            traceback.print_exc()
            sys.exit(1)

        device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
        print(f"[partial_fit] Using device: {device}")
        model.to(device)

        # --- seed replay buffer from train data ---
        replay = ReplayBuffer(capacity=replay_capacity)
        print("[partial_fit] Seeding replay buffer from train data...")
        
        all_train_batches = []
        try:
            for batch in train_iter:
                if batch is None:
                    break
                try:
                    x, y = batch
                    all_train_batches.append((x, y))
                except Exception:
                    continue
            
            print(f"[partial_fit] Collected {len(all_train_batches)} training batches")
            
            # Seed replay buffer from earlier batches (simulating previous tasks)
            num_seed_batches = max(1, len(all_train_batches) - 1) if len(all_train_batches) > 1 else 0
            for i in range(num_seed_batches):
                x, y = all_train_batches[i]
                replay.add_batch(x, y)
            
            print(f"[partial_fit] Seeded replay buffer with {len(replay)} samples from {num_seed_batches} batches")
        except Exception as e:
            print("[partial_fit] Warning: failed to seed replay buffer:", e)
            traceback.print_exc()

        # --- get new incoming data ---
        print("[partial_fit] Preparing new incoming data for continual learning...")
        X_new = None
        y_new = None
        
        if use_all_train and len(all_train_batches) > 0:
            # Use all training data (combine all batches)
            print("[partial_fit] Using ALL training data")
            X_list = []
            y_list = []
            for x, y in all_train_batches:
                x_t = x.detach().cpu() if isinstance(x, torch.Tensor) else torch.tensor(x, dtype=torch.float32)
                y_t = y.detach().cpu() if isinstance(y, torch.Tensor) else torch.tensor(y, dtype=torch.float32)
                X_list.append(x_t)
                y_list.append(y_t)
            X_new = torch.cat(X_list, dim=0)
            y_new = torch.cat(y_list, dim=0)
        else:
            # Use only the last batch as new data (simulating streaming)
            try:
                if len(all_train_batches) > 0:
                    X_new, y_new = all_train_batches[-1]
                    print("[partial_fit] Using last batch as new incoming data")
                else:
                    # Fallback: try to get from train_obj
                    if isinstance(train_obj, (list, tuple)):
                        if len(train_obj) == 0:
                            raise RuntimeError("train_loader list is empty")
                        X_new, y_new = train_obj[-1]
                    else:
                        # Get first batch
                        X_new, y_new = next(iter(train_obj))
            except Exception as e:
                print("[partial_fit] ERROR: could not obtain new batch from train_loader:", e)
                traceback.print_exc()
                sys.exit(1)

        # --- prepare mixed dataset (new data + replay samples) for continual learning ---
        try:
            X_new_t = X_new.detach().cpu() if isinstance(X_new, torch.Tensor) else torch.tensor(X_new, dtype=torch.float32)
            y_new_t = y_new.detach().cpu() if isinstance(y_new, torch.Tensor) else torch.tensor(y_new, dtype=torch.float32)
            
            print(f"[partial_fit] New data shape: X={X_new_t.shape}, y={y_new_t.shape}")
        except Exception as e:
            print("[partial_fit] ERROR converting new batch to tensors:", e)
            traceback.print_exc()
            sys.exit(1)

        try:
            X_rep_np, y_rep_np = replay.sample(replay_samples)
            if X_rep_np is not None and len(replay) > 0:
                X_rep_t = torch.tensor(X_rep_np, dtype=torch.float32)
                y_rep_t = torch.tensor(y_rep_np, dtype=torch.float32)
                ds_new = TensorDataset(X_new_t, y_new_t)
                ds_rep = TensorDataset(X_rep_t, y_rep_t)
                train_ds = ConcatDataset([ds_new, ds_rep])
                print(f"[partial_fit] Mixed dataset: {len(X_new_t)} new + {len(X_rep_t)} replay samples")
            else:
                train_ds = TensorDataset(X_new_t, y_new_t)
                print(f"[partial_fit] Using only new data: {len(X_new_t)} samples (no replay)")
        except Exception as e:
            print("[partial_fit] ERROR preparing mixed dataset:", e)
            traceback.print_exc()
            sys.exit(1)

        train_loader_local = DataLoader(train_ds, batch_size=batch_size, shuffle=True)

        # --- setup optimizer + loss ---
        optimizer = torch.optim.Adam(model.parameters(), lr=finetune_lr)
        
        if loss_name.lower().startswith('bce'):
            loss_fn = nn.BCEWithLogitsLoss()
        elif loss_name.lower().startswith('mse'):
            loss_fn = nn.MSELoss()
        elif loss_name.lower().startswith('cross'):
            loss_fn = nn.CrossEntropyLoss()
        else:
            loss_fn = nn.BCEWithLogitsLoss()
        
        print(f"[partial_fit] Using loss function: {loss_fn.__class__.__name__}")

        # save pre-update state for potential rollback
        model_ckpt = copy.deepcopy(model.state_dict())

        # --- partial-fit training (continual learning) ---
        print(f"[partial_fit] Starting continual learning for {finetune_epochs} epoch(s) with lr={finetune_lr:.6g}")
        model.train()
        last_loss = None
        
        try:
            for ep in range(finetune_epochs):
                running = 0.0
                total_n = 0
                num_batches = 0
                
                for xb, yb in train_loader_local:
                    xb = xb.to(device).float()
                    yb = yb.to(device).float()
                    
                    optimizer.zero_grad()
                    out = model(xb)
                    
                    # Handle different output shapes
                    if out.dim() > yb.dim():
                        out = out.squeeze(-1)
                    if yb.dim() > out.dim():
                        yb = yb.squeeze(-1)
                    
                    loss = loss_fn(out, yb)
                    loss.backward()
                    
                    # Gradient clipping for stability
                    torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)
                    
                    optimizer.step()
                    
                    bs = xb.size(0)
                    running += loss.item() * bs
                    total_n += bs
                    num_batches += 1
                
                last_loss = running / max(1, total_n)
                print(f"[partial_fit] Epoch {ep+1}/{finetune_epochs} - avg_loss={last_loss:.6f} ({num_batches} batches)")
        except Exception as e:
            print("[partial_fit] ERROR during finetuning:", e)
            traceback.print_exc()
            # rollback to previous in-memory state
            try:
                model.load_state_dict(model_ckpt)
                print("[partial_fit] Rolled back to previous model state")
            except Exception:
                pass
            sys.exit(1)

        # --- validate on test_iter ---
        print("[partial_fit] Running validation on test_loader...")
        model.eval()
        total = 0.0
        n = 0
        num_test_batches = 0
        
        try:
            with torch.no_grad():
                for batch in test_iter:
                    try:
                        xb, yb = batch
                    except Exception:
                        continue
                    
                    xb = xb.to(device).float()
                    yb = yb.to(device).float()
                    out = model(xb)
                    
                    # Handle different output shapes
                    if out.dim() > yb.dim():
                        out = out.squeeze(-1)
                    if yb.dim() > out.dim():
                        yb = yb.squeeze(-1)
                    
                    loss = loss_fn(out, yb)
                    bs = xb.size(0)
                    total += loss.item() * bs
                    n += bs
                    num_test_batches += 1
            
            val_loss = total / max(1, n) if n > 0 else None
            print(f"[partial_fit] Validation - loss={val_loss:.6f} ({num_test_batches} batches, {n} samples)")
        except Exception as e:
            print("[partial_fit] WARNING: validation failed:", e)
            traceback.print_exc()
            val_loss = None

        # --- save updated model automatically to output directory ---
        try:
            out_dir = args.updated_pth_dir
            os.makedirs(out_dir, exist_ok=True)
            out_path = os.path.join(out_dir, 'updated_model.pth')
            
            # Save with metadata
            checkpoint = {
                'model_state': model.state_dict(),
                'optimizer_state': optimizer.state_dict(),
                'train_loss': last_loss,
                'val_loss': val_loss,
                'config': model_config,
                'replay_buffer_size': len(replay)
            }
            
            torch.save(checkpoint, out_path)
            print("[partial_fit] Saved updated model checkpoint at:", out_path)
            print(f"[partial_fit] Checkpoint includes: model_state, optimizer_state, losses, config")
        except Exception as e:
            print("[partial_fit] ERROR saving checkpoint:", e)
            traceback.print_exc()
            # attempt to rollback in-memory
            try:
                model.load_state_dict(model_ckpt)
            except Exception:
                pass
            sys.exit(1)

        print("[partial_fit] Continual learning completed successfully.")
        print(f"[partial_fit] Final training loss: {last_loss:.6f}")
        if val_loss is not None:
            print(f"[partial_fit] Final validation loss: {val_loss:.6f}")
    args:
      - --model_object
      - {inputPath: model_object}
      - --pth_file
      - {inputPath: pth_file}
      - --train_loader
      - {inputPath: train_loader}
      - --test_loader
      - {inputPath: test_loader}
      - --input_dim
      - {inputValue: input_dim}
      - --model_config
      - {inputValue: model_config}
      - --updated_pth_dir
      - {outputPath: updated_pth_dir}
